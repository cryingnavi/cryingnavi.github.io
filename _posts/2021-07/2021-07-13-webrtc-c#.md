---
layout: post
title: Window용 WebRTC 앱 만들기
date: "2021-07-13 10:22"
categories: webrtc
tags: [webrtc, turn, C#]
published: false
---


## 개요
샘플용 UWP 어플리케이션을 제작함으로써 MixedReality-WebRTC를 이용해 어떻게 WebRTC 서비스를 구현할 수 있는지 단계별로 알아보도록 하겠습니다. 아래 단계를 모두 거치면, UWP 데스크탑 앱과 다른 피씨 또는 모바일 브라우저와 WebRTC로 화상 통신을 연결할 수 있을 것입니다.  

또한, 시그널 서버는 자체 구현한 시그널 서버를 사용할 것입니다. 해당 시그널 서버는 https://github.com/cryingnavi/webrtc-server를 참조하시면 됩니다. 해당 서버를 구동하는 방법과 통신 방법은 별도로 설명하겠습니다.

UWP가 무엇인지에 대하 자세히 알고 싶다면, https://docs.microsoft.com/ko-kr/windows/uwp/get-started/universal-application-platform-guide?OCID=VSClient_Ver17_UWPOverview_what-is-uwp를 참조하면 됩니다.


## 프로젝트 생성하기
유니버셜 프로젝트를 생성합니다. 저는 WebRTCEx02라는 이름으로 프로젝트를 생성했습니다. 
![프로젝트 생성하기](/assets/images/2021-07-12/webrtc01.png)
![프로젝트 생성하기](/assets/images/2021-07-12/webrtc02.png)

## MixedReality-WebRTC에 종속성 추가하기
MixedReality-WebRTC 종속성을 추가하기 위해서는 NuGet 패키지 도구를 이용합니다. NuGet은 Visual Studio에서 사용되는 무료 또는 오픈 소스 패키지를 관리해주는 도구로 GUI 환경에서 이를 다운로드 하고 관리할 수 있습니다.  
MixedReality-WebRTC는 NuGet을 이용해 종속성을 추가합니다. 

![종속성추가](/assets/images/2021-07-10/webrtc04.png)
![종속성추가](/assets/images/2021-07-12/webrtc03.png)

위와 같이 Microsoft.MixedReality.WebRTC를 검색해서 설치 합니다. 이번에는 반드시 Microsoft.MixedReality.WebRTC.UWP를 설치해야 합니다.

## 레이아웃 생성하기
MainPage.xaml 파일을 열고 아래와 같이 xml을 작성합니다.

```
<Page
	x:Class="WebRTCEX02.MainPage"
	xmlns="http://schemas.microsoft.com/winfx/2006/xaml/presentation"
	xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml"
	xmlns:local="using:WebRTCEX02"
	xmlns:d="http://schemas.microsoft.com/expression/blend/2008"
	xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"
	mc:Ignorable="d"
	Background="{ThemeResource ApplicationPageBackgroundThemeBrush}" d:DesignWidth="3833.333" d:DesignHeight="2231.481">

	<Grid>
		<Grid.ColumnDefinitions>
			<ColumnDefinition Width="5*"/>
			<ColumnDefinition Width="5*"/>
		</Grid.ColumnDefinitions>
		<Grid.RowDefinitions>
			<RowDefinition Height="5*"/>
			<RowDefinition Height="*"/>
			<RowDefinition Height="*"/>
		</Grid.RowDefinitions>

		<Border Grid.Row="0" Grid.Column="0" Background="#000"/>
		<Border Grid.Row="0" Grid.Column="1" Background="gray"/>

		<StackPanel Grid.Row="0" Grid.Column="0" Margin="20" VerticalAlignment="Center">
			<!-- 로컬 비디오 표시 -->
		</StackPanel>
		<StackPanel Grid.Row="0" Grid.Column="1" Margin="20" VerticalAlignment="Center">
			<!-- 리모트 비디오 표시 -->
		</StackPanel>
		<StackPanel Grid.Row="1" Grid.ColumnSpan="2" Orientation="Horizontal"
			HorizontalAlignment="Center" VerticalAlignment="Center">
			<TextBox Width="500" PlaceholderText="채팅방 아이디를 입력하세요"/>
		</StackPanel>

		<StackPanel Grid.Row="2" Grid.ColumnSpan="2" Orientation="Horizontal"
			HorizontalAlignment="Center" VerticalAlignment="Center">
			<Button Content="Start" Margin="10" />
			<Button Content="Call" Margin="10" />
			<Button Content="HangUp" Margin="10" />
		</StackPanel>
	</Grid>
</Page>
```

그럼 아래와 같은 레이아웃이 생성 될 것입니다. 검은색 바탕은 로컬 비디오가 표현될 공간이고 회색 바탕은 리모트 비디오가 표현될 공간입니다.

![레이아웃](/assets/images/2021-07-12/webrtc04.png)

## 권한 허용하기
WebRTC 어플리케이션은 웹캠, 마이크, 인터넷 액세스에 대한 권한을 가지고 있어야 합니다. 웹캠과 마이크는 당연히 장치에 접근해야하기 때문이고 인터넷은 다른 피어와 연결해야하기 때문에 권한 허용이 필요한 부분입니다.

![레이아웃](/assets/images/2021-07-12/webrtc05.png)
![레이아웃](/assets/images/2021-07-12/webrtc06.png)


## 로컬 비디오 표현하기
로컬 비디오를 표시하기 위해서는 VideoBridge라는 유틸리티가 필요합니다. 이는 캡처한 비디오 프레임을 수집해서 표시하는 역할을 수행합니다. 또한 VideoBridge는 StreamSamplePool 클래스를 사용합니다. 두 개의 소스는 각각 
https://github.com/microsoft/MixedReality-WebRTC/blob/master/examples/TestAppUwp/Video/VideoBridge.cs 와 https://github.com/microsoft/MixedReality-WebRTC/blob/master/examples/TestAppUwp/Video/StreamSamplePool.cs 에서 얻을 수 있습니다.

두개의 소스를 가져와 프로젝트에 포함 시킵니다.

![로컬 비디오](/assets/images/2021-07-12/webrtc07.png)

### 코딩하기
코딩할 게 많습니다. 일단 두개의 이벤트를 추가합니다. Loaded 이벤트는 어플리케이션이 실행되고 페이지가 로드 되면 호출됩니다. 웹에선 DOM에 접근할 수 있는 onload와 같습니다. Suspending 이벤트는 어플리케이션 전체가 일시 중지된 상태 곧 앱이 작업표시줄로 내려간다거나 할때 이벤트가 호출됩니다.

```
public MainPage()
{
	this.InitializeComponent();

	this.Loaded += OnLoaded;
	Application.Current.Suspending += App_Suspending;
}
```

### Loaded 이벤트 작성
아래는 Loaded 이벤트의 전체 소스 코드입니다. 
```
private async void OnLoaded(object sender, RoutedEventArgs e) {
	DeviceAudioTrackSource _microphoneSource;
	DeviceVideoTrackSource _webcamSource;
	LocalAudioTrack _localAudioTrack;
	LocalVideoTrack _localVideoTrack;

	_microphoneSource = await DeviceAudioTrackSource.CreateAsync();
	_webcamSource = await DeviceVideoTrackSource.CreateAsync();

	var audioTrackConfig = new LocalAudioTrackInitConfig {
		trackName = "microphone_track"
	};
	_localAudioTrack = LocalAudioTrack.CreateFromSource(_microphoneSource, audioTrackConfig);

	var videoTrackConfig = new LocalVideoTrackInitConfig {
		trackName = "webcam_track"
	};
	_webcamSource.I420AVideoFrameReady += LocalI420AFrameReady;
}
```

아래는 미디어 소스와 트랙을 저장하기 위한 변수 입니다.
```
DeviceAudioTrackSource _microphoneSource;
DeviceVideoTrackSource _webcamSource;
LocalAudioTrack _localAudioTrack;
LocalVideoTrack _localVideoTrack;
```

CreateAsync() 메소드로 미디어 소스를 얻어냅니다. 여기서는 인자로 아무것도 전달하지 않아 미디어 옵션이 기본값으로 사용됩니다.   
```
_microphoneSource = await DeviceAudioTrackSource.CreateAsync();
_webcamSource = await DeviceVideoTrackSource.CreateAsync();
```

만약 미디어에 대한 설정을 해야한다면 LocalAudioDeviceInitConfig, LocalVideoDeviceInitConfig를 사용할 수 있습니다. 사용법은 다음과 같습니다.

```
_microphoneSource = await DeviceAudioTrackSource.CreateAsync(new LocalAudioDeviceInitConfig() {
	AutoGainControl = true
});
_webcamSource = await DeviceVideoTrackSource.CreateAsync(new LocalVideoDeviceInitConfig() {
	framerate = 30.0,
	width = 640,
	enableMrc = true
});
```

- LocalAudioDeviceInitConfig

| 이름 | 설명 |
|------|------|
| AutoGainControl | AGC를 켜서 게인을 자동으로 조절합니다. 곧 강한 신호는 약하게 약한 신호는 강하게 증폭하게 됩니다. |


- LocalVideoDeviceInitConfig

| 이름 | 설명 |
|------|------|
| enableMrc | 홀로렌즈와 같은 혼합현실을 제공하는 장치에서 가상과 현실을 모두 캡쳐할지 여부를 지정함 |
| enableMrcRecordingIndicator | enableMrc가 true인경우, 카메라가 촬영하는 동안 적색원을 표시함 |
| framerate | 프레임레이트를 조절함 |
| width | 해상도 지정 |
| height | 해상도 지정 |
| videoDevice | 비디오 캡처 장치, 여러 비디오 장치가 있을 경우 그중 하나를 선택할 수 있다. |
| videoProfileId |  |
| videoProfileKind |  |


이제 비디오 트랙과 오디오 트랙을 생성합니다.
```
var audioTrackConfig = new LocalAudioTrackInitConfig {
	trackName = "microphone_track"
};
_localAudioTrack = LocalAudioTrack.CreateFromSource(_microphoneSource, audioTrackConfig);

var videoTrackConfig = new LocalVideoTrackInitConfig {
	trackName = "webcam_track"
};
_webcamSource.I420AVideoFrameReady += LocalI420AFrameReady;
```


### Suspending 이벤트 작성
```
private void App_Suspending(object sender, SuspendingEventArgs e) {
	localVideoPlayerElement.SetMediaPlayer(null);
}
```
Suspending 이벤트가 발생하면 비디오를 끕니다. 다시 실행하려면 어플리케이션을 재시작해야 합니다.


